---
title: "Faster and Cheaper LLMs: Quantization of LLMS"
description: "Model Compression using quantization"
dateString: Aug 2025
draft: false
tags: ["ML", "AI", "Python", "quantization", "gptq","awq", "llama3"]
weight: 107
---
# This Blog Is Still Under Progress